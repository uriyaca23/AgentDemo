# AgentDemo â€” Enterprise LLM Chat Agent

A full-stack AI chat application with **streaming LLM responses**, **web search tool use**, **AI image generation**, **multimodal input** (image attachments), and **conversation history persistence**. Built with a FastAPI backend and a Next.js 16 + React 19 frontend.

---

## ğŸ“‚ Project Structure

```
AgentDemo/
â”œâ”€â”€ api_key.txt               # OpenRouter API key (git-ignored, unlocked at runtime)
â”œâ”€â”€ pytest.ini                # Pytest config (asyncio auto mode)
â”œâ”€â”€ .gitignore                # Git exclusions
â”‚
â”œâ”€â”€ backend/                  # â”€â”€ FastAPI Backend â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”‚   â”œâ”€â”€ main.py               # App entry point, CORS, static mount, router wiring
â”‚   â”œâ”€â”€ database.py           # SQLAlchemy engine + SessionLocal factory
â”‚   â”œâ”€â”€ settings.py           # Runtime settings singleton (network toggle)
â”‚   â”‚
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ db_models.py      # SQLAlchemy ORM: ConversationDB table
â”‚   â”‚   â””â”€â”€ schemas.py        # Pydantic schemas: Message, ChatRequest, NetworkToggle, UnlockRequest
â”‚   â”‚
â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â”œâ”€â”€ chat.py           # POST /chat (streaming SSE), GET /chat/conversations
â”‚   â”‚   â”œâ”€â”€ models.py         # GET /models (aggregates internal + OpenRouter models)
â”‚   â”‚   â””â”€â”€ settings.py       # GET/PUT /settings/network-mode, API key unlock
â”‚   â”‚
â”‚   â””â”€â”€ services/
â”‚       â”œâ”€â”€ history.py        # CRUD helpers for ConversationDB
â”‚       â”œâ”€â”€ openrouter.py     # OpenRouter streaming proxy with tool-use (web_search)
â”‚       â””â”€â”€ skills.py         # @generate_image skill (Pollinations AI)
â”‚
â”œâ”€â”€ frontend/                 # â”€â”€ Next.js 16 Frontend â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”‚   â”œâ”€â”€ layout.tsx    # Root layout with Geist fonts
â”‚   â”‚   â”‚   â”œâ”€â”€ page.tsx      # Main chat page (client component)
â”‚   â”‚   â”‚   â””â”€â”€ globals.css   # Tailwind + custom scrollbar/animation styles
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ ApiKeyModal.tsx       # First-run unlock dialog
â”‚   â”‚   â”‚   â”œâ”€â”€ MarkdownRenderer.tsx  # Rich markdown with KaTeX, GFM, <think> tags, DSML scrubbing
â”‚   â”‚   â”‚   â”œâ”€â”€ ModelSelector.tsx     # Dropdown for model selection
â”‚   â”‚   â”‚   â””â”€â”€ Sidebar.tsx           # Conversation history sidebar
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ lib/
â”‚   â”‚       â””â”€â”€ utils.ts      # Utility: cn() for Tailwind class merging
â”‚   â”‚
â”‚   â””â”€â”€ __tests__/            # Jest + React Testing Library
â”‚       â”œâ”€â”€ ApiKeyModal.test.tsx
â”‚       â”œâ”€â”€ MarkdownRenderer.test.tsx
â”‚       â”œâ”€â”€ ModelSelector.test.tsx
â”‚       â”œâ”€â”€ Sidebar.test.tsx
â”‚       â”œâ”€â”€ layout.test.tsx
â”‚       â””â”€â”€ page.test.tsx
â”‚
â”œâ”€â”€ tests/                    # â”€â”€ Backend Pytest Suite â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”‚   â”œâ”€â”€ test_api_key.py       # API key file detection
â”‚   â”œâ”€â”€ test_backend_health.py # Root endpoint health check
â”‚   â”œâ”€â”€ test_chat.py          # Chat endpoint + skill interception
â”‚   â”œâ”€â”€ test_history.py       # Conversation CRUD operations
â”‚   â”œâ”€â”€ test_models.py        # Model listing endpoint
â”‚   â”œâ”€â”€ test_openrouter.py    # OpenRouter streaming, tool fallback, context retention
â”‚   â”œâ”€â”€ test_settings.py      # Network mode toggle
â”‚   â”œâ”€â”€ test_skills.py        # Image generation: success, retry, error paths
â”‚   â””â”€â”€ test_titling_model.py # Background title generation
â”‚
â”œâ”€â”€ docker/                   # â”€â”€ Containerization â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â””â”€â”€ openshift-deployment.yaml
â”‚
â”œâ”€â”€ docs/                     # â”€â”€ Documentation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”‚   â”œâ”€â”€ deployment_guide.md
â”‚   â””â”€â”€ prompts/              # Original planning prompts
â”‚       â”œâ”€â”€ init_prompt.txt
â”‚       â””â”€â”€ init_ui_plan.md.resolved
â”‚
â”œâ”€â”€ locked_secrets/           # â”€â”€ Encrypted credentials â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”‚   â”œâ”€â”€ api_key.zip           # AES-encrypted OpenRouter key
â”‚   â”œâ”€â”€ encrypt_key.py        # Script to re-encrypt the key
â”‚   â””â”€â”€ secrets.tar.gz        # Legacy archive
â”‚
â””â”€â”€ data/                     # â”€â”€ Runtime artifacts (git-ignored) â”€â”€â”€â”€â”€â”€
    â””â”€â”€ gen_*.jpg              # Locally saved generated images
```

---

## ğŸ—ï¸ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Browser (Next.js 16 @ localhost:3000)                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Sidebar   â”‚  â”‚ Chat Page    â”‚  â”‚ ModelSelector /       â”‚   â”‚
â”‚  â”‚ (history) â”‚  â”‚ (SSE stream) â”‚  â”‚ ApiKeyModal / Modes  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                        â”‚ POST /chat (SSE)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â–¸
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FastAPI Backend (@ localhost:8001)                            â”‚
â”‚                        â”‚                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¿â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  /chat router                                          â”‚  â”‚
â”‚  â”‚   1. Save to history (SQLite via SQLAlchemy)           â”‚  â”‚
â”‚  â”‚   2. Check for skill trigger (@generate_image)         â”‚  â”‚
â”‚  â”‚   3. If no skill â†’ proxy to OpenRouter (streaming)     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                               â”‚
â”‚  â”Œâ”€ Services â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                                                        â”‚   â”‚
â”‚  â”‚  openrouter.py                                         â”‚   â”‚
â”‚  â”‚  â”œâ”€â”€ Streaming SSE proxy to OpenRouter API             â”‚   â”‚
â”‚  â”‚  â”œâ”€â”€ Tool-use: web_search â†’ DDGS text + news scrape    â”‚   â”‚
â”‚  â”‚  â”œâ”€â”€ Auto-retry without tools if model rejects them    â”‚   â”‚
â”‚  â”‚  â””â”€â”€ Background title generation after first message   â”‚   â”‚
â”‚  â”‚                                                        â”‚   â”‚
â”‚  â”‚  skills.py                                             â”‚   â”‚
â”‚  â”‚  â”œâ”€â”€ @generate_image â†’ Pollinations AI (Flux model)    â”‚   â”‚
â”‚  â”‚  â”œâ”€â”€ 3-attempt retry with exponential backoff          â”‚   â”‚
â”‚  â”‚  â””â”€â”€ Saves generated images to /data/ directory        â”‚   â”‚
â”‚  â”‚                                                        â”‚   â”‚
â”‚  â”‚  history.py                                            â”‚   â”‚
â”‚  â”‚  â””â”€â”€ CRUD operations on ConversationDB (SQLite/JSON)   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¸ HTTPS
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  OpenRouter.ai API     â”‚
            â”‚  (GPT-4o, DeepSeek,    â”‚
            â”‚   Claude, Gemini, etc) â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Quick Start

### Prerequisites
- **Python 3.11+** with pip
- **Node.js 20+** with npm
- An **OpenRouter API key** (or unlock the encrypted one via the UI)

### 1. Backend

```bash
cd backend
pip install fastapi uvicorn sqlalchemy httpx ddgs beautifulsoup4 pyzipper
python -m uvicorn main:app --reload --port 8001
```

### 2. Frontend

```bash
cd frontend
npm install
npm run dev
```

Open **http://localhost:3000** in your browser.

### 3. API Key Setup

Either:
- Place your OpenRouter API key in `api_key.txt` at the project root, or
- Use the in-app unlock modal (it decrypts `locked_secrets/api_key.zip` with a password)

---

## ğŸ”Œ API Reference

| Method | Endpoint                          | Description                                       |
|--------|-----------------------------------|---------------------------------------------------|
| GET    | `/`                               | Health check                                      |
| GET    | `/models`                         | List available models (internal + OpenRouter)     |
| GET    | `/chat/conversations`             | List all conversations (newest first)             |
| GET    | `/chat/conversations/{id}`        | Load a single conversation with messages          |
| POST   | `/chat`                           | Stream a chat completion (SSE) or trigger a skill |
| GET    | `/settings/network-mode`          | Get online/offline toggle state                   |
| PUT    | `/settings/network-mode`          | Toggle online/offline mode                        |
| GET    | `/settings/api-key-status`        | Check if API key exists and is valid              |
| POST   | `/settings/unlock-key`            | Decrypt API key from zip with password            |
| GET    | `/data/{filename}`                | Serve generated images (static mount)             |

### POST `/chat` â€” Request Body

```json
{
  "messages": [{"role": "user", "content": "Hello!"}],
  "model": "openai/gpt-4o-mini",
  "mode": "auto",               // auto | fast | thinking | pro
  "conversation_id": null       // null = new conversation
}
```

### Response

Server-Sent Events (SSE) stream. Each event:

```
data: {"choices": [{"delta": {"content": "Hello! How can..."}}]}
```

Response header `x-conversation-id` contains the conversation UUID.

---

## ğŸ§ª Testing

### Backend Tests (pytest)

```bash
# From project root
python -m pytest tests/ -v
```

| Test File              | What It Covers                                                      |
|------------------------|---------------------------------------------------------------------|
| `test_backend_health`  | Root `/` endpoint returns 200                                       |
| `test_api_key`         | API key file detection and validation                               |
| `test_models`          | `/models` returns at least the internal model                       |
| `test_settings`        | Network mode toggle round-trip                                      |
| `test_history`         | Create, read, update, delete conversations                          |
| `test_chat`            | Chat endpoint streaming + skill interception                        |
| `test_openrouter`      | Mode injection, tool-call fallback, context retention               |
| `test_skills`          | Image gen success, retry on 530, permanent failure error message    |
| `test_titling_model`   | Background conversation title generation                            |

### Frontend Tests (Jest)

```bash
cd frontend
npx jest
```

| Test File                        | What It Covers                                    |
|----------------------------------|---------------------------------------------------|
| `ApiKeyModal.test.tsx`           | Modal rendering and dismiss behavior              |
| `MarkdownRenderer.test.tsx`      | Markdown, LaTeX, think-tag, DSML tag scrubbing    |
| `ModelSelector.test.tsx`         | Model dropdown rendering and selection            |
| `Sidebar.test.tsx`               | Conversation list rendering                       |
| `layout.test.tsx`                | Root layout structure                             |
| `page.test.tsx`                  | Main page rendering and UI state                  |

---

## ğŸ§  Key Features & Design Decisions

### Chat Modes
| Mode       | Behavior |
|------------|----------|
| **Auto**   | Model decides whether to use `<think>` reasoning tags |
| **Fast**   | Low temperature, 512 max tokens, concise responses |
| **Thinking** | Forces `<think>...</think>` step-by-step reasoning before answering |
| **Pro**    | Expert-level, detailed professional responses |

### Web Search (Tool Use)
- When **online**, the backend injects a `web_search` tool schema into the OpenRouter request.
- If the model calls `web_search`, the backend executes a DuckDuckGo search (text + news), scrapes top results, and feeds them back to the model for a grounded answer.
- If a model doesn't support tools (returns a 404/error), the backend retries without tools and injects a system notice explaining the limitation.

### Image Generation (`@generate_image`)
- Completely **bypasses the LLM** â€” a client-side skill trigger.
- Uses **Pollinations.ai** (free, no auth, Flux model) with 3-attempt retry.
- Saves generated images locally in `data/` and serves them via FastAPI static mount.
- On failure, returns a user-friendly error message (no raw HTTP codes leaked).

### DSML Tag Scrubbing
- Some models (notably DeepSeek) leak internal `< | DSML | function_calls >` XML tags into the response content.
- The `MarkdownRenderer` automatically strips these before rendering.

### Offline Mode
- Toggled via the UI header button.
- Disables tool injection (no web search), and instructs the model that it has no internet access.
- Model list always fetches from OpenRouter regardless (so you can still pick models).

---

## ğŸ³ Docker

```bash
cd docker
docker-compose up --build
```

See `docs/deployment_guide.md` for OpenShift deployment instructions.

---

## ğŸ“œ License

Internal project â€” not publicly licensed.
